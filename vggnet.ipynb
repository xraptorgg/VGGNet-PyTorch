{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:54.369828Z","iopub.status.busy":"2023-02-26T13:37:54.369035Z","iopub.status.idle":"2023-02-26T13:37:55.395260Z","shell.execute_reply":"2023-02-26T13:37:55.393885Z","shell.execute_reply.started":"2023-02-26T13:37:54.369785Z"},"trusted":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:55.399965Z","iopub.status.busy":"2023-02-26T13:37:55.399616Z","iopub.status.idle":"2023-02-26T13:37:56.710367Z","shell.execute_reply":"2023-02-26T13:37:56.709260Z","shell.execute_reply.started":"2023-02-26T13:37:55.399930Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision\n","from torchvision import datasets, transforms\n","from torch.utils.data import DataLoader\n","from torchvision.transforms import ToTensor\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:56.713777Z","iopub.status.busy":"2023-02-26T13:37:56.711837Z","iopub.status.idle":"2023-02-26T13:37:56.745869Z","shell.execute_reply":"2023-02-26T13:37:56.744510Z","shell.execute_reply.started":"2023-02-26T13:37:56.713719Z"},"trusted":true},"outputs":[],"source":["# device agnostic code\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","\n","device"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:56.751229Z","iopub.status.busy":"2023-02-26T13:37:56.750799Z","iopub.status.idle":"2023-02-26T13:37:56.756822Z","shell.execute_reply":"2023-02-26T13:37:56.755465Z","shell.execute_reply.started":"2023-02-26T13:37:56.751186Z"},"trusted":true},"outputs":[],"source":["# getting dataset\n","\n","# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n","\n","# wget did not work for this kaggle notebook, hence i manually downloaded the dataset and uploaded it to kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:56.759798Z","iopub.status.busy":"2023-02-26T13:37:56.758590Z","iopub.status.idle":"2023-02-26T13:37:57.407945Z","shell.execute_reply":"2023-02-26T13:37:57.406521Z","shell.execute_reply.started":"2023-02-26T13:37:56.759757Z"},"trusted":true},"outputs":[],"source":["# loading train data\n","\n","TRAINING_PATH = \"tiny-imagenet-200/train\"\n","\n","transform = transforms.Compose([\n","    transforms.Resize((227, 227)),\n","    transforms.ToTensor()\n","])\n","\n","training_data = datasets.ImageFolder(root = TRAINING_PATH, transform = transform, target_transform = None)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:57.410962Z","iopub.status.busy":"2023-02-26T13:37:57.410151Z","iopub.status.idle":"2023-02-26T13:37:58.885516Z","shell.execute_reply":"2023-02-26T13:37:58.883295Z","shell.execute_reply.started":"2023-02-26T13:37:57.410910Z"},"trusted":true},"outputs":[],"source":["# loading validation data\n","\n","VAL_PATH = \"tiny-imagenet-200/val\"\n","\n","\n","with open(\"tiny-imagenet-200/val/val_annotations.txt\") as f:\n","    lines = f.readlines()\n","    \n","val_dict = {}\n","\n","for line in lines:\n","    parts = line.strip().split('\\t')\n","    val_dict[parts[0]] = parts[1]\n","    \n","transform = transforms.Compose([\n","    transforms.Resize((227, 227)),\n","    transforms.ToTensor()\n","])\n","    \n","\n","val_data = datasets.ImageFolder(root = VAL_PATH, transform = transform, target_transform = None)\n","\n","for i in range(len(val_data)):\n","    img_path, _ = val_data.imgs[i]\n","    img_name = os.path.basename(img_path)\n","    val_data.imgs[i] = (img_path, training_data.classes.index(val_dict[img_name]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:58.888428Z","iopub.status.busy":"2023-02-26T13:37:58.887566Z","iopub.status.idle":"2023-02-26T13:37:58.918822Z","shell.execute_reply":"2023-02-26T13:37:58.916338Z","shell.execute_reply.started":"2023-02-26T13:37:58.888378Z"},"trusted":true},"outputs":[],"source":["# data shapes\n","\n","print(f\"Length of training data = {len(training_data)}, Shape of Image = {training_data[0][0].shape}\")\n","print(f\"Length of validation data = {len(val_data)}, Shape of Image = {val_data[0][0].shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:37:58.921231Z","iopub.status.busy":"2023-02-26T13:37:58.920497Z","iopub.status.idle":"2023-02-26T13:38:00.012278Z","shell.execute_reply":"2023-02-26T13:38:00.010811Z","shell.execute_reply.started":"2023-02-26T13:37:58.921154Z"},"trusted":true},"outputs":[],"source":["# label mapping file\n","with open(\"tiny-imagenet-200/words.txt\", 'r') as f:\n","    class_names = f.readlines()\n","    \n","# mapping between WordNet IDs to class names\n","class_dict = {}\n","for line in class_names:\n","    line = line.split('\\t')\n","    class_dict[line[0]] = line[1].strip()\n","    \n","    \n","# visualise\n","torch.manual_seed(1234)\n","fig = plt.figure(figsize=(12, 12))\n","rows, cols = 3, 3\n","for i in range(rows * cols):\n","    rand_idx = torch.randint(0, len(training_data), size = [1]).item()\n","    image, target = training_data[rand_idx]\n","    fig.add_subplot(rows, cols, i + 1)\n","    plt.imshow(image.permute(1, 2, 0))\n","    plt.title(class_dict[training_data.classes[target]])\n","    plt.axis(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.013733Z","iopub.status.busy":"2023-02-26T13:38:00.013405Z","iopub.status.idle":"2023-02-26T13:38:00.114893Z","shell.execute_reply":"2023-02-26T13:38:00.113710Z","shell.execute_reply.started":"2023-02-26T13:38:00.013701Z"},"trusted":true},"outputs":[],"source":["# dataloader\n","\n","BATCH_SIZE = 16\n","\n","training_dataloader = DataLoader(dataset = training_data, batch_size = BATCH_SIZE, shuffle = True)\n","val_dataloader = DataLoader(dataset = val_data, batch_size = BATCH_SIZE, shuffle = True)\n","\n","training_images, training_targets = next(iter(training_dataloader))\n","\n","print(f\"Training images batch shape = {training_images.shape}\")\n","print(f\"Training targets batch shape = {training_targets.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.117083Z","iopub.status.busy":"2023-02-26T13:38:00.116692Z","iopub.status.idle":"2023-02-26T13:38:00.138353Z","shell.execute_reply":"2023-02-26T13:38:00.136925Z","shell.execute_reply.started":"2023-02-26T13:38:00.117044Z"},"trusted":true},"outputs":[],"source":["# VGG-16 model\n","\n","class VGG16(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 5, stride = 2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.conv_block_3 = nn.Sequential(\n","            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.conv_block_4 = nn.Sequential(\n","            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.conv_block_5 = nn.Sequential(\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features = 7 * 7 * 512, out_features = 4096),\n","            nn.Linear(in_features = 4096, out_features = 4096),\n","            nn.Linear(in_features = 4096, out_features = num_classes)\n","        )\n","        self.init_weights()\n","\n","    # xavier initialization\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                nn.init.zeros_(m.bias)\n","        \n","    \n","    def forward(self, x):\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        x = self.conv_block_3(x)\n","        x = self.conv_block_4(x)\n","        x = self.conv_block_5(x)\n","        return self.classifier(x)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# VGG-19 model\n","\n","class VGG19(nn.Module):\n","    def __init__(self, num_classes):\n","        super().__init__()\n","\n","        self.conv_block_1 = nn.Sequential(\n","            nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, stride = 1, padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 5, stride = 2)\n","        )\n","\n","        self.conv_block_2 = nn.Sequential(\n","            nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.conv_block_3 = nn.Sequential(\n","            nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 256, out_channels = 256, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.conv_block_4 = nn.Sequential(\n","            nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.conv_block_5 = nn.Sequential(\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.Conv2d(in_channels = 512, out_channels = 512, kernel_size = 3, stride = 1,padding = 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size = 2, stride = 2)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(),\n","            nn.Linear(in_features = 7 * 7 * 512, out_features = 4096),\n","            nn.Linear(in_features = 4096, out_features = 4096),\n","            nn.Linear(in_features = 4096, out_features = num_classes)\n","        )\n","        self.init_weights()\n","\n","    def init_weights(self):\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.xavier_uniform_(m.weight)\n","                if m.bias is not None:\n","                    nn.init.zeros_(m.bias)\n","            elif isinstance(m, nn.Linear):\n","                nn.init.xavier_uniform_(m.weight)\n","                nn.init.zeros_(m.bias)            \n","        \n","    \n","    def forward(self, x):\n","        x = self.conv_block_1(x)\n","        x = self.conv_block_2(x)\n","        x = self.conv_block_3(x)\n","        x = self.conv_block_4(x)\n","        x = self.conv_block_5(x)\n","        return classifier(x)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.142693Z","iopub.status.busy":"2023-02-26T13:38:00.142314Z","iopub.status.idle":"2023-02-26T13:38:00.150850Z","shell.execute_reply":"2023-02-26T13:38:00.149583Z","shell.execute_reply.started":"2023-02-26T13:38:00.142641Z"},"trusted":true},"outputs":[],"source":["# train and test metrics \n","\n","train_loss_values = []\n","val_loss_values = []\n","val_acc_values = []\n","epoch_count = []"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.155103Z","iopub.status.busy":"2023-02-26T13:38:00.154543Z","iopub.status.idle":"2023-02-26T13:38:00.169042Z","shell.execute_reply":"2023-02-26T13:38:00.167569Z","shell.execute_reply.started":"2023-02-26T13:38:00.155065Z"},"trusted":true},"outputs":[],"source":["# training loop\n","\n","def model_train(epochs, model, train_dataloader, val_dataloader, loss_func, optimizer, scheduler):\n","\n","    # turn on training mode\n","    model.train()\n","\n","    #check training device\n","    print(f\"Training on {device}.\")\n","\n","    # loop through each epoch\n","    for epoch in range(epochs):\n","        print(f\"Epoch: {epoch + 1}/{epochs}\\n-------------\")\n","\n","        # loop through each batch\n","        train_loss, train_acc = 0, 0\n","        total_steps = 1\n","        for images, classes in train_dataloader:\n","\n","            #send data to device\n","            images, classes = images.to(device), classes.to(device)\n","\n","            # computer forward pass\n","            y_pred = model(images)\n","\n","            # compute loss\n","            loss = loss_func(y_pred, classes)\n","            train_loss += loss\n","            train_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1))\n","\n","            # update weights\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            batch_loss = train_loss / total_steps\n","            batch_acc = train_acc / total_steps\n","\n","            if total_steps % 10 == 0:\n","                print(f\"Training Loss: {batch_loss:.5f} - Training Accuracy: {batch_acc:.5f}%\")\n","\n","            total_steps += 1\n","\n","\n","        # performance on test set\n","        # turn on inference mode\n","        with torch.inference_mode():\n","            # loop through each batch\n","            total_val_loss, val_acc = 0, 0\n","            for val_images, val_classes in val_dataloader:\n","                # send data to device\n","                val_images, val_classes = val_images.to(device), val_classes.to(device)\n","\n","                # forward pass\n","                y_val_pred = model(val_images)\n","\n","                # compute loss\n","                val_loss = loss_func(y_val_pred, val_classes)\n","                total_val_loss += val_loss\n","                val_acc += accuracy_fn(y_true = val_classes, y_pred = y_val_pred.argmax(dim=1)\n","                )\n","            \n","            total_val_loss /= len(val_dataloader)\n","            val_acc /= len(val_dataloader)\n","\n","            # learning rate decay\n","            scheduler.step(val_acc)\n","\n","        train_loss /= len(train_dataloader)\n","        train_acc /= len(train_dataloader)\n","\n","        print(f\"[After {epoch + 1} epochs: Train Loss: {train_loss:.5f} - Train Accuracy: {train_acc:.5f}% - Validation Loss: {total_val_loss:.5f} - Validation Accuracy: {val_acc:.5f}%]\")\n","\n","        \n","        train_loss_values.append(train_loss.item())\n","        val_loss_values.append(total_val_loss.item())\n","        val_acc_values.append(val_acc)\n","        epoch_count.append(epoch + 1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.175344Z","iopub.status.busy":"2023-02-26T13:38:00.174635Z","iopub.status.idle":"2023-02-26T13:38:00.184534Z","shell.execute_reply":"2023-02-26T13:38:00.182597Z","shell.execute_reply.started":"2023-02-26T13:38:00.175304Z"},"trusted":true},"outputs":[],"source":["# test loop\n","\n","def model_test(model, dataloader, loss_func):\n","    # turn on test mode\n","    model.eval()\n","    \n","    # turn on inference mode\n","    with torch.inference_mode():\n","        # loop through each batch\n","        test_loss, test_acc = 0, 0\n","        for images, classes in dataloader:\n","            # send data to device\n","            images, classes = images.to(device), classes.to(device)\n","\n","            # forward pass\n","            y_pred = model(images)\n","\n","            # compute loss\n","            loss = loss_func(y_pred, classes)\n","            test_loss += loss\n","            test_acc += accuracy_fn(y_true = classes, y_pred = y_pred.argmax(dim=1)\n","            )\n","        \n","        test_loss /= len(dataloader)\n","        test_acc /= len(dataloader)\n","        print(f\"Loss: {test_loss:.5f} - Accuracy: {test_acc:.5f}%\")\n","        return test_acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.187504Z","iopub.status.busy":"2023-02-26T13:38:00.186471Z","iopub.status.idle":"2023-02-26T13:38:00.197113Z","shell.execute_reply":"2023-02-26T13:38:00.196253Z","shell.execute_reply.started":"2023-02-26T13:38:00.187460Z"},"trusted":true},"outputs":[],"source":["# metric functions\n","\n","def accuracy_fn(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","    return acc"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:00.199777Z","iopub.status.busy":"2023-02-26T13:38:00.198864Z","iopub.status.idle":"2023-02-26T13:38:02.362046Z","shell.execute_reply":"2023-02-26T13:38:02.360901Z","shell.execute_reply.started":"2023-02-26T13:38:00.199736Z"},"trusted":true},"outputs":[],"source":["# instantiating model\n","\n","torch.manual_seed(1234)\n","vgg_16 = VGG16(200).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-02-26T13:38:02.364547Z","iopub.status.busy":"2023-02-26T13:38:02.363624Z","iopub.status.idle":"2023-02-26T13:38:02.372411Z","shell.execute_reply":"2023-02-26T13:38:02.371127Z","shell.execute_reply.started":"2023-02-26T13:38:02.364504Z"},"trusted":true},"outputs":[],"source":["# loss function and optimizer\n","\n","LEARNING_RATE = 0.0001\n","\n","loss_func = nn.CrossEntropyLoss()\n","\n","sgd = torch.optim.SGD(params = vgg_16.parameters(), lr = LEARNING_RATE, momentum = 0.9, weight_decay = 0.0005)\n","\n","learning_decay = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer = sgd, mode = \"max\", factor = 0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# training the model\n","\n","EPOCHS = 90\n","\n","\n","torch.manual_seed(1234)\n","model_train(epochs = EPOCHS, model = vgg_16, train_dataloader = training_dataloader, val_dataloader = val_dataloader, loss_func = loss_func, optimizer = sgd, scheduler = learning_decay)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# evaluating the model\n","\n","accuracy = model_test(model = alexnet, dataloader = val_dataloader, loss_func = loss_func)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# loss curve\n","\n","plt.figure(figsize=(13, 7))\n","plt.plot(epoch_count, train_loss_values, label = \"Train loss\")\n","plt.plot(epoch_count, test_loss_values, label = \"Test loss\")\n","plt.title(\"Loss curves\")\n","plt.ylabel(\"Loss\")\n","plt.xlabel(\"Epochs\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# accuracy curve\n","\n","plt.figure(figsize=(13, 7))\n","plt.plot(epoch_count, test_acc_values, label = \"Accuracy\")\n","plt.title(\"Accuracy curves\")\n","plt.ylabel(\"Accuracy\")\n","plt.xlabel(\"Epochs\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# saving the model\n","\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents = True, exist_ok = True)\n","\n","MODEL_NAME = \"VGGNet_\" + str(accuracy).replace(\".\", \"_\") + \".pth\"\n","\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","print(f\"Saving AlexNet to {MODEL_SAVE_PATH}\")\n","torch.save(obj = alexnet.state_dict(), f = MODEL_SAVE_PATH)"]}],"metadata":{"kernelspec":{"display_name":"deep_learning_pytorch","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"},"vscode":{"interpreter":{"hash":"6c2160265d74b9ae3c2113401ab035a10c81631044ed747ffca0db5c3a8a7eb0"}}},"nbformat":4,"nbformat_minor":4}
